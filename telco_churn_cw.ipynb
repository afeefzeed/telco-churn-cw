{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afeefzeed/telco-churn-cw/blob/main/telco_churn_cw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeSEmoOsdmwH"
      },
      "outputs": [],
      "source": [
        "# Install required libraries (run once)\n",
        "!pip install -q pandas numpy matplotlib seaborn scikit-learn tensorflow keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from tensorflow import keras\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "print('Libraries imported')"
      ],
      "metadata": {
        "id": "6zl9FnbDtVqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL A: Choose & load dataset (Colab friendly) ----------\n",
        "# Use browser upload OR mount Google Drive. This cell saves chosen file to working dir.\n",
        "from google.colab import files\n",
        "import os, io, pandas as pd, numpy as np\n",
        "\n",
        "print(\"Choose upload method:\\n1) Upload file from computer\\n2) Use file already in Colab working dir\\n3) Mount Google Drive (enter path manually)\")\n",
        "choice = input(\"Enter 1/2/3 (press Enter for 1): \").strip() or \"1\"\n",
        "\n",
        "if choice == \"1\":\n",
        "    uploaded = files.upload()\n",
        "    # take the first uploaded file\n",
        "    fname = list(uploaded.keys())[0]\n",
        "    path = fname\n",
        "    print(\"Uploaded:\", path)\n",
        "elif choice == \"2\":\n",
        "    path = input(\"Enter filename in working dir (e.g., Telco-Customer-Churn.csv): \").strip()\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"{path} not found in working dir\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    path = input(\"Enter full path to file in Drive (e.g., /content/drive/MyDrive/Colab Notebooks/Telco-Customer-Churn.csv): \").strip()\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"{path} not found\")\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(path)\n",
        "print(\"Loaded:\", path, \" — shape:\", df.shape)\n",
        "\n",
        "# Quick fix: show top columns and first rows\n",
        "display(df.head())\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "MWB4cKUreiLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL B:  EDA (feature signal & actionable insights) ----------\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# 1) basic dtype & missing diagnostics\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nMissing values (top):\")\n",
        "print(df.isna().sum().sort_values(ascending=False).head(20))\n",
        "\n",
        "# 2) TotalCharges quick check (Telco-specific)\n",
        "if 'TotalCharges' in df.columns:\n",
        "    print(\"\\nTotalCharges dtype before fix:\", df['TotalCharges'].dtype)\n",
        "    # Count spaces\n",
        "    spaces = (df['TotalCharges'].astype(str).str.strip() == \"\").sum()\n",
        "    print(\"TotalCharges blank-strings:\", spaces)\n",
        "    # show few bad rows\n",
        "    display(df[df['TotalCharges'].astype(str).str.strip()==\"\"].head())\n",
        "\n",
        "# 3) Target balance & class-wise numeric summary\n",
        "target_col = 'Churn' if 'Churn' in df.columns else ('y' if 'y' in df.columns else None)\n",
        "if target_col is None:\n",
        "    raise ValueError(\"Cannot find target column named 'Churn' or 'y'\")\n",
        "\n",
        "print(f\"\\nTarget column: {target_col}\")\n",
        "display(df[target_col].value_counts())\n",
        "print(\"\\nPercentage:\")\n",
        "display((df[target_col].value_counts(normalize=True)*100).round(2))\n",
        "\n",
        "# Numeric columns overview & class-wise means for top numeric cols\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(\"\\nNumeric columns:\", num_cols)\n",
        "if len(num_cols) > 0:\n",
        "    # show class-wise means for numeric columns\n",
        "    display(df.groupby(target_col)[num_cols].mean().T.head(10))\n",
        "\n",
        "# 4) Mutual information (fast signal ranking)\n",
        "# prepare a short cleaned copy: convert simple binary yes/no to 0/1 and drop id-like cols\n",
        "prep = df.copy()\n",
        "# quick conversion for obvious binary columns\n",
        "for c in prep.select_dtypes(include=['object']).columns:\n",
        "    if prep[c].nunique() == 2:\n",
        "        prep[c] = prep[c].map({prep[c].unique()[0]:0, prep[c].unique()[1]:1})\n",
        "# for mutual info we need numeric features; convert remaining object columns to codes (fast, not final!)\n",
        "for c in prep.select_dtypes(include=['object']).columns:\n",
        "    prep[c] = prep[c].astype('category').cat.codes\n",
        "X_mi = prep.drop(columns=[target_col], errors='ignore').select_dtypes(include=[np.number])\n",
        "y_mi = prep[target_col].astype(int)\n",
        "mi = mutual_info_classif(X_mi.fillna(0), y_mi, discrete_features='auto', random_state=42)\n",
        "mi_series = pd.Series(mi, index=X_mi.columns).sort_values(ascending=False)\n",
        "print(\"\\nTop mutual information features (fast):\")\n",
        "display(mi_series.head(15))\n",
        "\n",
        "# 5) Quick permutation importance using a shallow Decision Tree (fast)\n",
        "print(\"\\nPermutation importance (shallow DecisionTree, fast):\")\n",
        "small_dt = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
        "# sample small balanced subset if data is large\n",
        "sample_idx = df.index\n",
        "if len(df) > 5000:\n",
        "    sample_idx = df.sample(5000, random_state=42).index\n",
        "X_perm = X_mi.loc[sample_idx].fillna(0)\n",
        "y_perm = y_mi.loc[sample_idx]\n",
        "small_dt.fit(X_perm, y_perm)\n",
        "perm = permutation_importance(small_dt, X_perm, y_perm, n_repeats=8, random_state=42, n_jobs=1)\n",
        "perm_series = pd.Series(perm.importances_mean, index=X_perm.columns).sort_values(ascending=False)\n",
        "display(perm_series.head(15))\n",
        "\n",
        "# 6) PCA projection (2D) of top-K numeric features\n",
        "top_feats = mi_series.head(8).index.tolist()\n",
        "if len(top_feats) >= 2:\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    proj = pca.fit_transform(prep[top_feats].fillna(0))\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.scatterplot(x=proj[:,0], y=proj[:,1], hue=prep[target_col].astype(str), alpha=0.6, s=40)\n",
        "    plt.title('PCA (2D) projection on top features — colored by target')\n",
        "    plt.show()\n",
        "\n",
        "# 7) Compact actionable plots (contract vs churn, payment vs churn, tenure bins)\n",
        "if 'Contract' in df.columns:\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(data=df, x='Contract', hue=target_col)\n",
        "    plt.title('Contract type vs Churn'); plt.xticks(rotation=45); plt.show()\n",
        "\n",
        "if 'PaymentMethod' in df.columns:\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(data=df, x='PaymentMethod', hue=target_col)\n",
        "    plt.title('PaymentMethod vs Churn'); plt.xticks(rotation=45); plt.show()\n",
        "\n",
        "# tenure bins\n",
        "if 'tenure' in df.columns:\n",
        "    df['tenure_bin'] = pd.cut(df['tenure'], bins=[-1,0,12,24,48,72], labels=['None','0-12','13-24','25-48','49-72'])\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(data=df, x='tenure_bin', hue=target_col)\n",
        "    plt.title('Tenure bins vs Churn'); plt.show()\n",
        "    # drop created column to avoid contaminating pipeline\n",
        "    df.drop(columns=['tenure_bin'], inplace=True, errors='ignore')\n",
        "\n",
        "print(\"\\nEDA done — use these signals to pick features & engineering steps.\")\n"
      ],
      "metadata": {
        "id": "LBe_nRITetzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Advanced Visualization Cell ---\n",
        "if 'df' in globals():\n",
        "    # 1) Target distribution\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.countplot(x='Churn', data=df)\n",
        "    plt.title('Churn Distribution')\n",
        "    plt.show()\n",
        "\n",
        "    # 2) Tenure bins vs churn\n",
        "    df['tenure_bin'] = pd.cut(df['tenure'], bins=[-1,12,24,48,72],\n",
        "                              labels=['0-12','13-24','25-48','49-72'])\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(data=df, x='tenure_bin', hue='Churn')\n",
        "    plt.title('Tenure Groups vs Churn')\n",
        "    plt.show()\n",
        "\n",
        "    # 3) MonthlyCharges distribution split by churn\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.kdeplot(data=df, x='MonthlyCharges', hue='Churn', fill=True, common_norm=False)\n",
        "    plt.title('Monthly Charges Distribution by Churn')\n",
        "    plt.show()\n",
        "\n",
        "    # 4) Internet Service vs Churn\n",
        "    if 'InternetService' in df.columns:\n",
        "        plt.figure(figsize=(8,4))\n",
        "        sns.countplot(data=df, x='InternetService', hue='Churn')\n",
        "        plt.title('Internet Service vs Churn')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.show()\n",
        "\n",
        "    # Clean temporary column\n",
        "    df.drop(columns=['tenure_bin'], inplace=True, errors='ignore')\n",
        "else:\n",
        "    print(\"Load dataset first.\")\n"
      ],
      "metadata": {
        "id": "fGqpW-a2exE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Improved Correlation Analysis Cell ---\n",
        "if 'df' in globals():\n",
        "\n",
        "    # 1) Numeric Correlation Heatmap\n",
        "    num = df.select_dtypes(include=[np.number])\n",
        "    if num.shape[1] > 1:\n",
        "        plt.figure(figsize=(12,8))\n",
        "        sns.heatmap(num.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
        "        plt.title('Numeric Feature Correlation Heatmap')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Not enough numeric columns for numeric correlation.\")\n",
        "\n",
        "    # 2) Correlation of numeric features WITH Churn\n",
        "    if 'churn' in df.columns:\n",
        "        churn_corr = num.corr()['Churn'].sort_values(ascending=False)\n",
        "\n",
        "        plt.figure(figsize=(6,5))\n",
        "        sns.barplot(x=churn_corr.values, y=churn_corr.index, palette=\"viridis\")\n",
        "        plt.title(\"Correlation of Numeric Features with Churn\")\n",
        "        plt.xlabel(\"Correlation Value\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Churn column missing; cannot compute correlation with target.\")\n",
        "\n",
        "else:\n",
        "    print(\"Load the dataset first.\")\n"
      ],
      "metadata": {
        "id": "S0rje4e_e1Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# FINAL CLEANING + PREPROCESSING PIPELINE\n",
        "# ================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import joblib\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPROCESSING PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---- 1. WORKING COPY ----\n",
        "df_clean = df.copy()\n",
        "print(f\"\\n✓ Step 1: Created working copy\")\n",
        "print(f\"  Original shape: {df_clean.shape}\")\n",
        "\n",
        "# ---- 2. FIX TotalCharges ----\n",
        "if 'TotalCharges' in df_clean.columns:\n",
        "    blank_count = (df_clean['TotalCharges'].astype(str).str.strip() == \"\").sum()\n",
        "    df_clean['TotalCharges'] = df_clean['TotalCharges'].replace(\" \", np.nan)\n",
        "    df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors=\"coerce\")\n",
        "    df_clean['TotalCharges'] = df_clean['TotalCharges'].fillna(\n",
        "        df_clean['MonthlyCharges'] * df_clean['tenure']\n",
        "    )\n",
        "    print(f\"\\n✓ Step 2: Fixed TotalCharges column\")\n",
        "    print(f\"  - Found {blank_count} blank entries\")\n",
        "    print(f\"  - Imputed using: MonthlyCharges × tenure\")\n",
        "    print(f\"  - Remaining nulls: {df_clean['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# ---- 3. DROP NON-USEFUL ID COLUMNS ----\n",
        "id_cols = ['customerID', 'CustomerID', 'customerId']\n",
        "dropped_ids = [c for c in id_cols if c in df_clean.columns]\n",
        "df_clean = df_clean.drop(columns=dropped_ids, errors='ignore')\n",
        "print(f\"\\n✓ Step 3: Dropped ID columns\")\n",
        "if dropped_ids:\n",
        "    print(f\"  - Removed: {dropped_ids}\")\n",
        "else:\n",
        "    print(f\"  - No ID columns found\")\n",
        "\n",
        "# ---- 4. ENCODE TARGET ----\n",
        "original_target_dist = df_clean['Churn'].value_counts()\n",
        "df_clean['Churn'] = df_clean['Churn'].map({'Yes':1, 'No':0}).astype(int)\n",
        "print(f\"\\n✓ Step 4: Encoded target variable\")\n",
        "print(f\"  - 'Yes' → 1 (Churn)\")\n",
        "print(f\"  - 'No' → 0 (No Churn)\")\n",
        "print(f\"  - Class distribution: {dict(df_clean['Churn'].value_counts())}\")\n",
        "print(f\"  - Imbalance ratio: {(df_clean['Churn']==1).sum() / len(df_clean) * 100:.1f}% churn\")\n",
        "\n",
        "# ---- 5. FEATURE GROUPS ----\n",
        "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "binary_cols  = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "cat_cols     = [c for c in df_clean.select_dtypes(include='object').columns if c != 'Churn']\n",
        "print(f\"\\n✓ Step 5: Identified feature groups\")\n",
        "print(f\"  - Numeric features ({len(numeric_cols)}): {numeric_cols}\")\n",
        "print(f\"  - Binary features ({len(binary_cols)}): {binary_cols}\")\n",
        "print(f\"  - Categorical features ({len(cat_cols)}): {cat_cols}\")\n",
        "\n",
        "# ---- 6. FIX BINARY YES/NO ----\n",
        "binary_converted = []\n",
        "for col in binary_cols:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = df_clean[col].map({'Yes':1, 'No':0}).astype('float')\n",
        "        binary_converted.append(col)\n",
        "print(f\"\\n✓ Step 6: Converted binary features to 0/1\")\n",
        "print(f\"  - Converted: {binary_converted}\")\n",
        "\n",
        "# ---- 7. FILL MISSING CATEGORICAL VALUES ----\n",
        "filled_cats = []\n",
        "for col in cat_cols:\n",
        "    missing_before = df_clean[col].isnull().sum()\n",
        "    if missing_before > 0:\n",
        "        df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])\n",
        "        filled_cats.append((col, missing_before))\n",
        "print(f\"\\n✓ Step 7: Filled missing categorical values\")\n",
        "if filled_cats:\n",
        "    for col, count in filled_cats:\n",
        "        print(f\"  - {col}: filled {count} missing values with mode\")\n",
        "else:\n",
        "    print(f\"  - No missing categorical values found\")\n",
        "\n",
        "# ---- 8. BUILD PREPROCESSOR ----\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_cols),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_cols),\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "print(f\"\\n✓ Step 8: Built ColumnTransformer\")\n",
        "print(f\"  - StandardScaler for numeric features\")\n",
        "print(f\"  - OneHotEncoder for categorical features (drop_first=True)\")\n",
        "print(f\"  - Binary features passed through as-is\")\n",
        "\n",
        "# ---- 9. TRAIN-TEST SPLIT ----\n",
        "X = df_clean.drop(columns=['Churn'])\n",
        "y = df_clean['Churn']\n",
        "X_train_raw, X_test_raw, y_train_raw, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "print(f\"\\n✓ Step 9: Train-test split (80/20, stratified)\")\n",
        "print(f\"  - Training set: {X_train_raw.shape[0]} samples\")\n",
        "print(f\"  - Test set: {X_test_raw.shape[0]} samples\")\n",
        "print(f\"  - Train class distribution: {dict(Counter(y_train_raw))}\")\n",
        "print(f\"  - Test class distribution: {dict(Counter(y_test))}\")\n",
        "\n",
        "# ---- 10. FIT TRANSFORMER ----\n",
        "preprocessor.fit(X_train_raw)\n",
        "X_train = preprocessor.transform(X_train_raw)\n",
        "X_test  = preprocessor.transform(X_test_raw)\n",
        "try:\n",
        "    ohe = preprocessor.named_transformers_['cat']\n",
        "    ohe_feature_count = len(ohe.get_feature_names_out())\n",
        "    total_features = len(numeric_cols) + ohe_feature_count + len(binary_cols)\n",
        "except:\n",
        "    total_features = X_train.shape[1]\n",
        "print(f\"\\n✓ Step 10: Applied transformations\")\n",
        "print(f\"  - Training features shape: {X_train.shape}\")\n",
        "print(f\"  - Test features shape: {X_test.shape}\")\n",
        "print(f\"  - Total features after encoding: {total_features}\")\n",
        "\n",
        "# ---- 11. SMOTE BALANCING ----\n",
        "print(f\"\\n✓ Step 11: Applying SMOTE for class balancing\")\n",
        "print(f\"  - Before SMOTE: {dict(Counter(y_train_raw))}\")\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train_raw)\n",
        "print(f\"  - After SMOTE: {dict(Counter(y_train_bal))}\")\n",
        "print(f\"  - Training samples increased: {X_train.shape[0]} → {X_train_bal.shape[0]}\")\n",
        "print(f\"  - Class balance achieved: 50/50 split\")\n",
        "\n",
        "# ---- 12. SAVE PREPROCESSOR ----\n",
        "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
        "print(f\"\\n✓ Step 12: Saved preprocessor\")\n",
        "print(f\"  - File: preprocessor.joblib\")\n",
        "\n",
        "# ---- FINAL SUMMARY ----\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PREPROCESSING COMPLETE ✓\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Final Training Set: {X_train_bal.shape[0]} samples × {X_train_bal.shape[1]} features\")\n",
        "print(f\"Final Test Set: {X_test.shape[0]} samples × {X_test.shape[1]} features\")\n",
        "print(f\"Ready for model training!\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# ---- 13. ASSIGN FINAL VARIABLES ----\n",
        "X_train = X_train_bal\n",
        "y_train = y_train_bal\n",
        "\n",
        "print(\"Variable assignments:\")\n",
        "print(\"  X_train = SMOTE-balanced training features\")\n",
        "print(\"  y_train = SMOTE-balanced training labels\")\n",
        "print(\"  X_test = original test features (no SMOTE)\")\n",
        "print(\"  y_test = original test labels (no SMOTE)\")"
      ],
      "metadata": {
        "id": "_vLNkR7NfHVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL D: DecisionTree + GridSearch (tuned) ----------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "if 'X_train' in globals():\n",
        "    param_grid = {'max_depth':[4,6,8,12,16], 'criterion':['gini','entropy'], 'min_samples_leaf':[1,5,10]}\n",
        "    dt = DecisionTreeClassifier(random_state=42)\n",
        "    grid = GridSearchCV(dt, param_grid, cv=4, scoring='f1', n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_dt = grid.best_estimator_\n",
        "    print(\"Best DT params:\", grid.best_params_)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_dt = best_dt.predict(X_test)\n",
        "    print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "    print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred_dt)\n",
        "    sns.heatmap(cm, annot=True, fmt='d'); plt.title(\"Decision Tree Confusion Matrix\"); plt.show()\n",
        "\n",
        "    # Map feature importances back to names (try to reconstruct)\n",
        "    try:\n",
        "        # get feature names from preprocessor\n",
        "        num_cols = preprocessor.transformers_[0][2]\n",
        "        ohe = preprocessor.transformers_[1][1]\n",
        "        cat_cols = preprocessor.transformers_[1][2]\n",
        "        ohe_names = []\n",
        "        if hasattr(ohe, 'get_feature_names_out'):\n",
        "            ohe_names = list(ohe.get_feature_names_out(cat_cols))\n",
        "        feature_names = list(num_cols) + ohe_names + [c for c in X_train_raw.columns if c not in num_cols+cat_cols]\n",
        "        fi = pd.Series(best_dt.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
        "        display(fi.head(15))\n",
        "    except Exception as e:\n",
        "        print(\"Could not map feature names:\", e)\n",
        "else:\n",
        "    print(\"Run preprocessing first.\")\n"
      ],
      "metadata": {
        "id": "IUoVb8DWgYrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL E: Neural Network (improved training + callbacks) ----------\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'X_train' in globals():\n",
        "    input_dim = X_train.shape[1]\n",
        "    nn = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    rl = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "    history = nn.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.15, callbacks=[es, rl], verbose=2)\n",
        "\n",
        "    # plot history\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1); plt.plot(history.history['loss'], label='train'); plt.plot(history.history['val_loss'], label='val'); plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2); plt.plot(history.history['accuracy'], label='train'); plt.plot(history.history['val_accuracy'], label='val'); plt.legend(); plt.title('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluate\n",
        "    loss, acc = nn.evaluate(X_test, y_test, verbose=0)\n",
        "    print(\"NN Test Acc:\", acc)\n",
        "\n",
        "    y_prob_nn = nn.predict(X_test).ravel()\n",
        "    y_pred_nn = (y_prob_nn >= 0.5).astype(int)\n",
        "    print(classification_report(y_test, y_pred_nn))\n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred_nn), annot=True, fmt='d'); plt.title(\"NN Confusion Matrix\"); plt.show()\n",
        "\n",
        "    # save model\n",
        "    nn.save('nn_model.h5')\n",
        "    print(\"Neural net saved to nn_model.h5\")\n",
        "else:\n",
        "    print(\"Run preprocessing first.\")\n"
      ],
      "metadata": {
        "id": "5ZxtTDPtuFW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL F: ROC & AUC comparison ----------\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "if 'best_dt' in globals() and 'nn' in globals():\n",
        "    y_prob_dt = best_dt.predict_proba(X_test)[:,1]\n",
        "    fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)\n",
        "    auc_dt = auc(fpr_dt, tpr_dt)\n",
        "\n",
        "    fpr_nn, tpr_nn, _ = roc_curve(y_test, y_prob_nn)\n",
        "    auc_nn = auc(fpr_nn, tpr_nn)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(fpr_dt, tpr_dt, label=f'DT (AUC={auc_dt:.3f})')\n",
        "    plt.plot(fpr_nn, tpr_nn, label=f'NN (AUC={auc_nn:.3f})')\n",
        "    plt.plot([0,1],[0,1],'k--')\n",
        "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend(); plt.title('ROC Curves');\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Train both models first.\")\n"
      ],
      "metadata": {
        "id": "CFeOzPDvuIck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- FINAL MODEL COMPARISON ----------\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate metrics for both models\n",
        "dt_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_dt),\n",
        "    'Precision': precision_score(y_test, y_pred_dt),\n",
        "    'Recall': recall_score(y_test, y_pred_dt),\n",
        "    'F1-Score': f1_score(y_test, y_pred_dt),\n",
        "    'AUC': auc_dt\n",
        "}\n",
        "\n",
        "nn_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_nn),\n",
        "    'Precision': precision_score(y_test, y_pred_nn),\n",
        "    'Recall': recall_score(y_test, y_pred_nn),\n",
        "    'F1-Score': f1_score(y_test, y_pred_nn),\n",
        "    'AUC': auc_nn\n",
        "}\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Decision Tree': dt_metrics,\n",
        "    'Neural Network': nn_metrics\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "display(comparison_df.round(4))\n",
        "\n",
        "# Determine best model\n",
        "best_model = 'Neural Network' if nn_metrics['F1-Score'] > dt_metrics['F1-Score'] else 'Decision Tree'\n",
        "print(f\"\\n✓ Best performing model: {best_model}\")\n",
        "print(f\"  (Based on F1-Score: balances precision and recall)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Save comparison\n",
        "comparison_df.to_csv('model_comparison.csv')\n",
        "print(\"✓ Comparison saved to model_comparison.csv\")"
      ],
      "metadata": {
        "id": "aYyx2lMPwA8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='Contract', hue='Churn')\n",
        "plt.title(\"Contract vs Churn\")\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(data=df, x='PaymentMethod', hue='Churn')\n",
        "plt.title(\"PaymentMethod vs Churn\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(data=df, x='InternetService', hue='Churn')\n",
        "plt.title(\"InternetService vs Churn\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H-EQwM1j8WsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}